# AI Consulting Firm - Complete System Architecture Guide

## ğŸ¯ WHAT THIS APPLICATION DOES

This is an **AI-powered consulting firm simulator** that replaces human consultants with specialized AI agents. It takes your project documents and/or conversational input, then automatically generates professional consulting deliverables:

1. **Discovery Report** - Business analysis, requirements, stakeholders
2. **Scope of Work (SOW)** - Executive summary, success criteria, detailed scope, acceptance criteria
3. **Technical Architecture** - System components, infrastructure, security
4. **Implementation Roadmap** - Phased timeline with milestones

### The Magic:
Instead of paying a consulting firm $50k-$200k for these documents over weeks/months, you get them in minutes through intelligent AI orchestration.

---

## ğŸ—ï¸ SYSTEM ARCHITECTURE OVERVIEW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ui_app.py (Streamlit)                                      â”‚ â”‚
â”‚  â”‚  â€¢ Conversational UI                                        â”‚ â”‚
â”‚  â”‚  â€¢ File upload                                              â”‚ â”‚
â”‚  â”‚  â€¢ Discovery status tracking                                â”‚ â”‚
â”‚  â”‚  â€¢ Real-time progress logging                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ORCHESTRATION LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  main.py (Conductor)                                        â”‚ â”‚
â”‚  â”‚  â€¢ Coordinates all modules                                  â”‚ â”‚
â”‚  â”‚  â€¢ Manages iterative refinement loop                        â”‚ â”‚
â”‚  â”‚  â€¢ Handles validation gates                                 â”‚ â”‚
â”‚  â”‚  â€¢ Triggers exports                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚               â”‚               â”‚
             â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ProjectAssessor â”‚ â”‚   ExpertTeam    â”‚ â”‚ ValidationEngine â”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                  â”‚
â”‚ â€¢ Analyzes docs â”‚ â”‚ â€¢ 11 AI roles   â”‚ â”‚ â€¢ Quality checks â”‚
â”‚ â€¢ Determines    â”‚ â”‚ â€¢ Role prompts  â”‚ â”‚ â€¢ Contradiction  â”‚
â”‚   maturity      â”‚ â”‚ â€¢ Generation    â”‚ â”‚   detection      â”‚
â”‚                 â”‚ â”‚   orchestration â”‚ â”‚ â€¢ SOW completenessâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ModelClient    â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ Mock provider â”‚
                    â”‚ â€¢ OpenAI        â”‚
                    â”‚ â€¢ Ollama        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MODULE-BY-MODULE BREAKDOWN

### 1. **config.py** - Configuration Management
**Purpose:** Centralized settings using environment variables

**Key Settings:**
```python
MODEL_PROVIDER = "mock"  # mock | openai | ollama
MODEL_NAME = "gpt-4o"    # or llama3.1:8b for Ollama
MODEL_TEMPERATURE = 0.2  # Low = consistent outputs
MODEL_MAX_TOKENS = 4096

OUTPUT_PATH = "outputs"
TEMPLATES_PATH = "templates"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OLLAMA_HOST = "http://localhost:11434"
```

**How it works:**
- Reads from `.env` file or system environment
- Provides defaults if not set
- Used by all modules for consistent configuration

---

### 2. **model_client.py** - AI Model Abstraction Layer

**Purpose:** Pluggable interface to different AI providers

**11 Role Definitions:**
```python
ROLE_PROMPTS = {
    # Business & Strategy
    "strategist": "Analyze business viability, ROI, strategic alignment"
    "analyst": "Gather requirements, map stakeholders, identify gaps"
    "product": "Prioritize features, define MVP, ensure business value"
    
    # Technical
    "architect": "Design system architecture and components"
    "fullstack": "Validate implementation feasibility"
    "ml": "Assess AI/ML feasibility and data requirements"
    "ux": "Define user journeys and experience requirements"
    "devops": "Plan deployment, infrastructure, monitoring"
    "security": "Identify security controls and threats"
    "data": "Design data flows and storage"
    
    # Management
    "pm": "Provide timelines, milestones, risk management"
}
```

**Provider Support:**

**A) Mock Provider:**
```python
# Returns deterministic placeholder text for testing
"[Mock strategist response about project strategy...]"
```

**B) OpenAI Provider:**
```python
# Calls OpenAI ChatCompletion API
openai.ChatCompletion.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": role_prompt},
        {"role": "user", "content": task}
    ]
)
```

**C) Ollama Provider:**
```python
# Calls local Ollama HTTP endpoint
POST http://localhost:11434/api/generate
{
    "model": "llama3.1:8b",
    "prompt": "combined_prompt",
    "stream": false
}
# Returns: {"response": "AI generated text..."}
```

**How it works:**
1. `ModelClient` initialized with provider choice
2. `generate(role, prompt)` method called
3. Role-specific system prompt combined with task prompt
4. Appropriate provider API invoked
5. Response text returned

---

### 3. **project_assessor.py** - Project Maturity Detection

**Purpose:** Analyze existing documents to determine project stage

**Maturity Levels:**
- **Greenfield Discovery** - No documents; blank slate
- **Concept Validation** - Basic description exists
- **Requirements Defined** - Has requirements/SOW
- **Architecture Defined** - Has technical architecture
- **Implementation Ready** - Has detailed specs + architecture

**How it works:**
```python
def assess(project_path: str) -> str:
    docs_dir = project_path + "/project_documents"
    
    # Count files
    file_count = count_files(docs_dir)
    
    # Keyword analysis
    has_requirements = any("requirement" in filename)
    has_architecture = any("architecture" in filename)
    has_sow = any("sow" or "scope" in filename)
    
    # Total content size
    total_size = sum(file sizes)
    
    # Return maturity level based on heuristics
```

**Why this matters:**
- **Greenfield** â†’ AI needs to ask more questions
- **Architecture Defined** â†’ AI can focus on implementation details
- Helps AI tailor its questions and depth

---

### 4. **expert_team.py** - The Heart of the System

**Purpose:** Orchestrates 11 specialized AI roles to produce deliverables

**The Generation Flow:**

#### Phase 1: Discovery Report
```python
# 5 roles collaborate
1. Strategist: Business goals, ROI, strategic alignment
2. Analyst: Stakeholders, requirements, gaps, risks
3. PM: High-level timeline and milestones
4. ML Specialist: AI feasibility, data needs
5. UX Strategist: User journeys, experience requirements

# Output: 01_discovery_report.md
```

#### Phase 2: Scope of Work (SOW)
```python
# 9 roles contribute sections
EXECUTIVE SUMMARY       â†’ Strategist (ROI, business case)
SUCCESS CRITERIA        â†’ Product Owner (KPIs, metrics)
SCOPE & DELIVERABLES    â†’ Analyst (features + acceptance criteria)
ACCEPTANCE CRITERIA     â†’ Product Owner (measurable outcomes)
TECHNICAL APPROACH      â†’ Architect (system design)
AI FEASIBILITY          â†’ ML Specialist (data, models, infra)
UX REQUIREMENTS         â†’ UX Strategist (flows, constraints)
PROJECT MANAGEMENT      â†’ PM (timeline, resources, risks)
ASSUMPTIONS & CONSTRAINTS â†’ PM (dependencies, limits)

# Output: 02_scope_of_work.md
```

#### Phase 3: Technical Architecture
```python
# 4 roles define technical details
1. Architect: Components, connections (A -> B format)
2. Full-Stack Dev: Implementation validation
3. DevOps: Infrastructure, deployment topology
4. Security: Controls, compliance, threats

# Output: 03_technical_architecture.md
```

#### Phase 4: Implementation Roadmap
```python
# 2 roles plan execution
1. PM: Phased roadmap (MVP â†’ Enhancements â†’ Scale)
2. DevOps: Deployment gates, verification steps

# Output: 04_implementation_roadmap.md
```

**Document Context Ingestion:**
```python
def _gather_project_context(project_path):
    # Read files from project_path/project_documents/
    # Concatenate up to 8000 chars
    # Return as context string
    
    # This context is injected into EVERY role's prompt:
    "Provided Documents:
    ---
    File: System Architecture.docx
    [content...]
    ---
    File: Statement of Work.docx
    [content...]"
```

**Progress Logging:**
```python
self._log("ğŸ“‹ Reading project context...")
self._log("ğŸ‘” Strategist analyzing business viability...")
self._log("ğŸ“Š Business Analyst gathering requirements...")
# ... logs sent to UI in real-time via callback
```

---

### 5. **validation_engine.py** - Quality Assurance

**Purpose:** Validate outputs for completeness and consistency

**Three Validation Types:**

#### A) Presence & Quality Checks
```python
for each artifact:
    - File exists? âœ“/âœ—
    - File size > 100 bytes? âœ“/âœ—
    - Contains excessive jargon? âš ï¸
```

#### B) Cross-Artifact Contradiction Detection
```python
# Timeline contradictions
Discovery says: "6-month project"
SOW says: "12-week implementation"
â†’ Flag: Timeline mismatch detected

# Tech stack contradictions
Architecture mentions: PostgreSQL
SOW mentions: MongoDB
â†’ Flag: Database choice conflict
```

#### C) SOW Completeness Evaluation
```python
Required sections:
âœ“ EXECUTIVE SUMMARY
âœ“ SUCCESS CRITERIA
âœ“ SCOPE & DELIVERABLES
âœ“ ACCEPTANCE CRITERIA
âœ“ TECHNICAL APPROACH
âœ“ AI FEASIBILITY & DATA REQUIREMENTS
âœ“ UX & USER EXPERIENCE REQUIREMENTS
âœ“ PROJECT MANAGEMENT
âœ“ ASSUMPTIONS & CONSTRAINTS

# Must have 100+ words in each section
# Must have bullet points or numbered lists
```

**Validation Report Output:**
```markdown
# Validation Report

## Artifact: sow (02_scope_of_work.md)
- Status: PRESENT (size=5432 bytes)
- Quality: OK
- Client Readiness: Contains jargon (api, microservice, k8s)

## Cross-artifact: Timeline contradictions detected
- discovery: mentions duration 6 months
- sow: mentions duration 12 weeks

## SOW Completeness: PASS âœ“
All required sections present and sufficiently detailed.
```

---

### 6. **main.py** - The Conductor (Orchestration)

**Purpose:** Coordinates the entire pipeline with iterative refinement

**The Iterative Loop:**

```python
for round in [1, 2, 3]:  # Max 3 refinement rounds
    
    # Step 1: Generate all artifacts
    artifacts = expert_team.run(
        project_path,
        maturity,
        previous_sow=previous_draft,  # Feed prior draft for refinement
        feedback=validator_feedback   # Feed validation issues
    )
    
    # Step 2: Validate outputs
    validation_report = validator.validate(artifacts)
    
    # Step 3: Check SOW completeness
    complete, missing, notes = validator.evaluate_sow(sow_text)
    
    if complete:
        break  # Exit loop - we're done!
    else:
        # Prepare feedback for next round
        feedback = f"Missing: {missing}. Notes: {notes}"
        previous_draft = current_sow_text
        # Loop continues...
```

**Why Iterative?**
- First pass might miss sections
- Validator provides specific feedback
- AI refines on second/third pass
- Ensures completeness

**Export Pipeline:**
```python
if do_export:
    # 1. Generate PDFs from markdown
    pdf = document_generator.generate_from_markdown(sow_md, format='pdf')
    
    # 2. Generate architecture diagram
    diagram = generate_architecture_diagram(tech_md)
    
    # 3. Create combined DOCX
    docx = export_to_docx(all_artifacts)
    
    # 4. Create combined PDF
    pdf = export_to_pdf(all_artifacts)
```

---

### 7. **ui_app.py** - Streamlit User Interface

**Purpose:** Conversational web interface for non-technical users

**Layout Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI Consulting Firm                         â”‚
â”‚  [âš™ï¸ Advanced Settings] (collapsed)                     â”‚
â”‚  [ğŸ“ Upload documents]                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LEFT (70%)                   â”‚ RIGHT (30%)              â”‚
â”‚ ğŸ’¬ Conversation & Discovery  â”‚ ğŸ“Š Status & Controls     â”‚
â”‚                              â”‚                          â”‚
â”‚ [Welcome message]            â”‚ ğŸ—‚ï¸ Uploaded Files       â”‚
â”‚                              â”‚ â€¢ System Arch.docx âœ“    â”‚
â”‚ AI: "I've reviewed your..."  â”‚ â€¢ SOW.docx âœ“            â”‚
â”‚                              â”‚                          â”‚
â”‚ User: "Timeline is 6 months" â”‚ ğŸ“‹ Discovery Status     â”‚
â”‚                              â”‚ âœ“ Project Goals         â”‚
â”‚ AI: "Got it. What about..."  â”‚ âœ“ Target Users         â”‚
â”‚                              â”‚ â–¡ Key Features         â”‚
â”‚ [Text input box]             â”‚ â–¡ Tech Stack           â”‚
â”‚                              â”‚ â–¡ Timeline             â”‚
â”‚                              â”‚ [Progress: 2/5]        â”‚
â”‚                              â”‚                          â”‚
â”‚                              â”‚ [ğŸš€ Generate] (disabled)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Conversation Flow:**

#### Scenario A: Documents Present (Cold Start)
```python
# On page load
if has_documents and no_messages_yet:
    # AI analyzes documents
    file_summary = analyze_uploaded_files(docs_dir)
    
    # AI generates opening statement
    ai_opening = generate_cold_start_from_documents(docs_dir, model)
    # Example: "I've reviewed your System Architecture and SOW. 
    # I see you're using microservices. Are you committed to this 
    # approach? Your SOW mentions 6 months - is this still accurate?"
    
    # AI message added to chat automatically
    st.session_state.messages.append(ai_opening)
```

#### Scenario B: No Documents (User Starts)
```python
# User types first message
user_input = "I need an AI fitness coaching app"

# AI responds with context-aware questions
ai_response = generate_initial_response(user_input, has_files=False, model)
# Example: "Great idea! Who are your target users? What specific 
# fitness activities will you track? Do you have AI models already?"
```

**Discovery Status Tracking:**
```python
def check_context_sufficiency(messages):
    user_text = combine_all_user_messages(messages)
    
    checks = {
        'goals': ['goal', 'objective', 'purpose', 'mission'],
        'users': ['user', 'customer', 'stakeholder', 'persona'],
        'features': ['feature', 'functionality', 'capability', 'mvp'],
        'tech_stack': ['technology', 'stack', 'platform', 'framework'],
        'timeline': ['timeline', 'deadline', 'schedule', 'month']
    }
    
    status = {}
    for area, keywords in checks.items():
        status[area] = any(keyword in user_text for keyword in keywords)
    
    # Sufficient if 3+ of 5 areas covered
    is_sufficient = sum(status.values()) >= 3
    
    return is_sufficient, status
```

**Smart Generate Button:**
```python
# Button logic
generate_disabled = (
    not context_sufficient  # Need 3/5 discovery areas
    or generation_done      # Already generated
)

if context_sufficient:
    show "âœ… Ready to generate!"
elif generation_done:
    show "âœ“ Generation complete"
else:
    show "â³ Continue conversation..."
```

**Real-Time Activity Logging:**
```python
def ui_log(message):
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    
    # Store in session state
    st.session_state.activity_log.append(log_entry)
    
    # Update UI in real-time
    display_last_20_logs()
```

---

## ğŸ”„ END-TO-END EXECUTION FLOW

### Step-by-Step: What Happens When You Click "Generate"

```
1. UI collects conversation history
   â””â”€> Writes to: project_path/project_documents/consultation_notes.md

2. UI calls main.run() with log_callback
   â””â”€> Sends progress messages back to UI

3. ProjectAssessor analyzes documents
   â””â”€> Returns: "Architecture Defined" maturity level

4. Main.run() starts refinement loop (max 3 rounds)
   
   ROUND 1:
   â”œâ”€> ExpertTeam.run() called
   â”‚   â”œâ”€> Reads all files from project_documents/
   â”‚   â”œâ”€> Injects document context into every role prompt
   â”‚   â”‚
   â”‚   â”œâ”€> Discovery Report generation:
   â”‚   â”‚   â”œâ”€> Strategist analyzes business viability
   â”‚   â”‚   â”œâ”€> Analyst gathers requirements
   â”‚   â”‚   â”œâ”€> PM outlines timeline
   â”‚   â”‚   â”œâ”€> ML Specialist assesses AI feasibility
   â”‚   â”‚   â””â”€> UX Strategist defines user journeys
   â”‚   â”‚   â””â”€> Writes: 01_discovery_report.md
   â”‚   â”‚
   â”‚   â”œâ”€> SOW generation (9 role contributions):
   â”‚   â”‚   â”œâ”€> Executive Summary (Strategist)
   â”‚   â”‚   â”œâ”€> Success Criteria (Product Owner)
   â”‚   â”‚   â”œâ”€> Scope & Deliverables (Analyst)
   â”‚   â”‚   â”œâ”€> Acceptance Criteria (Product Owner)
   â”‚   â”‚   â”œâ”€> Technical Approach (Architect)
   â”‚   â”‚   â”œâ”€> AI Feasibility (ML Specialist)
   â”‚   â”‚   â”œâ”€> UX Requirements (UX Strategist)
   â”‚   â”‚   â”œâ”€> Project Management (PM)
   â”‚   â”‚   â””â”€> Assumptions & Constraints (PM)
   â”‚   â”‚   â””â”€> Writes: 02_scope_of_work.md
   â”‚   â”‚
   â”‚   â”œâ”€> Technical Architecture:
   â”‚   â”‚   â”œâ”€> Architect designs components (A -> B format)
   â”‚   â”‚   â”œâ”€> Full-Stack validates implementation
   â”‚   â”‚   â”œâ”€> DevOps plans infrastructure
   â”‚   â”‚   â””â”€> Security reviews compliance
   â”‚   â”‚   â””â”€> Writes: 03_technical_architecture.md
   â”‚   â”‚
   â”‚   â””â”€> Implementation Roadmap:
   â”‚       â”œâ”€> PM creates phased roadmap
   â”‚       â””â”€> DevOps adds deployment gates
   â”‚       â””â”€> Writes: 04_implementation_roadmap.md
   â”‚
   â”œâ”€> ValidationEngine.validate() called
   â”‚   â”œâ”€> Checks file presence/quality
   â”‚   â”œâ”€> Detects contradictions
   â”‚   â””â”€> Writes: validation_report.md
   â”‚
   â””â”€> ValidationEngine.evaluate_sow() called
       â”œâ”€> Checks all 9 required sections present
       â”œâ”€> Checks each section > 100 words
       â”‚
       IF complete:
       â”‚   â””â”€> PASS âœ“ - Exit loop
       ELSE:
       â”‚   â”œâ”€> Generate feedback: "Missing: UX section. Notes: ..."
       â”‚   â””â”€> ROUND 2 starts with feedback...
       
   ROUND 2: (if needed)
   â””â”€> Same flow, but with:
       â€¢ previous_sow passed to AI for refinement
       â€¢ feedback passed to focus on missing sections
       
   ROUND 3: (if needed)
   â””â”€> Final refinement attempt

5. Export phase (if do_export=True):
   â”œâ”€> DocumentGenerator converts markdown â†’ PDF
   â”œâ”€> Generate architecture diagram (PNG or DOT)
   â”œâ”€> Create combined DOCX of all artifacts
   â””â”€> Create combined PDF of all artifacts

6. Return to UI:
   â”œâ”€> Show "âœ… Generation complete!"
   â”œâ”€> Display activity log
   â”œâ”€> Show validation report inline
   â””â”€> Enable download buttons for all outputs
```

---

## ğŸ­ THE 11 AI ROLES EXPLAINED

Each role has a specific expertise area and contributes to specific deliverables:

### Business & Strategy Roles

**1. Strategist**
- **Expertise:** Business viability, ROI, market positioning
- **Contributes to:** Discovery Report (business goals), SOW (executive summary)
- **Example output:** "This project targets the $X billion fitness market. Expected ROI of 200% within 18 months based on 10K user acquisition..."

**2. Business Analyst**
- **Expertise:** Requirements gathering, stakeholder mapping
- **Contributes to:** Discovery Report (requirements), SOW (scope & deliverables)
- **Example output:** "Primary stakeholders: end users (fitness enthusiasts), coaches (admin interface), platform operators. Requirements: user authentication, workout tracking, AI recommendations..."

**3. Product Owner**
- **Expertise:** Feature prioritization, MVP definition
- **Contributes to:** SOW (success criteria, acceptance criteria)
- **Example output:** "Success measured by: 80% user retention after 30 days, <2s average response time, 4.5+ app store rating..."

### Technical Roles

**4. Solution Architect**
- **Expertise:** System design, component architecture
- **Contributes to:** SOW (technical approach), Tech Architecture (component diagram)
- **Example output:** "Mobile App -> API Gateway -> Auth Service -> Workout Service -> ML Inference Engine -> Database"

**5. Full-Stack Developer**
- **Expertise:** Implementation feasibility, effort estimation
- **Contributes to:** Tech Architecture (validation)
- **Example output:** "Implementation realistic using React Native + Node.js backend. Estimated 8-12 weeks for MVP. Key risks: ML model integration latency..."

**6. ML/AI Specialist**
- **Expertise:** AI feasibility, data requirements, model selection
- **Contributes to:** Discovery Report (AI assessment), SOW (AI feasibility section)
- **Example output:** "AI recommendation engine requires: 10K+ labeled workout sessions for training. Collaborative filtering + content-based hybrid model. Infrastructure: GPU inference (AWS Sagemaker or similar)..."

**7. UX/UI Strategist**
- **Expertise:** User experience, design requirements
- **Contributes to:** Discovery Report (user journeys), SOW (UX requirements)
- **Example output:** "Key user flows: Onboarding (3-step), Workout Selection (browse/search), Progress Tracking (dashboard). Design constraints: accessible (WCAG 2.1), responsive (mobile-first)..."

**8. DevOps Engineer**
- **Expertise:** Infrastructure, deployment, monitoring
- **Contributes to:** Tech Architecture (infra notes), Roadmap (deployment gates)
- **Example output:** "Deploy architecture: Kubernetes on AWS EKS. CI/CD: GitHub Actions â†’ Docker â†’ ECR â†’ EKS. Monitoring: Prometheus + Grafana. Blue-green deployment for zero-downtime updates..."

**9. Security Analyst**
- **Expertise:** Security controls, compliance, threat modeling
- **Contributes to:** Tech Architecture (security section)
- **Example output:** "Security controls: OAuth 2.0 + JWT, data encryption at rest (AES-256), TLS 1.3 in transit. Threats: account takeover (mitigate: MFA), data breach (mitigate: encryption + access controls). Compliance: GDPR (EU users), HIPAA (health data)..."

**10. Data Engineer**
- **Expertise:** Data pipelines, storage, ETL
- **Contributes to:** Tech Architecture (data flows)
- **Example output:** "Data flow: App â†’ API â†’ PostgreSQL (transactional) â†’ Airflow ETL â†’ S3 Data Lake â†’ Redshift (analytics). Real-time: Kafka for event streaming..."

### Management Role

**11. Project Manager**
- **Expertise:** Timeline, milestones, risk management
- **Contributes to:** Discovery Report (timeline), SOW (project management), Roadmap (phased plan)
- **Example output:** "Phase 1 (8 weeks): MVP with core features. Phase 2 (4 weeks): AI recommendations. Phase 3 (6 weeks): Analytics & admin. Risks: ML model accuracy (mitigate: 2-week buffer), third-party API changes (mitigate: abstraction layer)..."

---

## ğŸ”§ HOW ROLES ARE ORCHESTRATED

### Prompt Engineering Structure

Each role receives:
1. **Role-specific system prompt** (defines expertise)
2. **Project context** (uploaded documents + conversation)
3. **Task-specific instruction** (what to produce)

Example for Architect role in SOW:

```python
# 1. Role prompt (from ROLE_PROMPTS)
"You are a senior solution architect. Produce a clear, non-jargon 
architecture description and component list."

# 2. Project context (from _gather_project_context)
"Project path: RLFuturesSystemDocs
Maturity: Architecture Defined

Provided Documents:
---
File: System Architecture.docx
[4000 chars of content...]
---
File: Statement of Work.docx
[4000 chars of content...]
---
File: consultation_notes.md
User: I need comprehensive deliverables for RL Futures
Assistant: I've reviewed your architecture. Is 6-month timeline accurate?
User: Yes, 6 months with 5-person team
..."

# 3. Task instruction
"Provide system architecture, data flows, integrations, and security 
considerations for the SOW Technical Approach section."

# Combined prompt sent to AI:
"You are a senior solution architect...
[full context]
Provide system architecture, data flows..."
```

### Role Sequencing

Roles are called in logical order:

**Discovery Phase:**
```
Strategist â†’ Analyst â†’ PM â†’ ML â†’ UX
(Business first, then technical details)
```

**SOW Phase:**
```
Strategist (exec summary)
â†’ Product (success criteria)
â†’ Analyst (scope details)
â†’ Product (acceptance criteria)
â†’ Architect (technical approach)
â†’ ML (AI feasibility)
â†’ UX (experience requirements)
â†’ PM (project management)
â†’ PM (assumptions/constraints)
```

**Architecture Phase:**
```
Architect â†’ Full-Stack â†’ DevOps â†’ Security
(Design first, validate, then ops + security)
```

**Roadmap Phase:**
```
PM â†’ DevOps
(Plan phases, then add deployment details)
```

---

## ğŸ” THE ITERATIVE REFINEMENT LOOP

### Why Iteration?

LLMs can miss requirements or produce incomplete outputs on first pass. Iteration ensures quality.

### How It Works:

**Round 1: Initial Generation**
```python
artifacts = expert_team.run(
    project_path,
    maturity,
    previous_sow=None,      # No prior draft
    feedback=None           # No feedback yet
)

# Result: SOW might be missing UX section or have sparse content
```

**Validation Check:**
```python
complete, missing, notes = validator.evaluate_sow(sow_text)

if not complete:
    missing = ["UX Requirements"]
    notes = ["UX section only 45 words (need 100+)"]
    
    feedback = "Missing sections: UX Requirements. 
                Notes: UX section only 45 words (need 100+)"
```

**Round 2: Refinement**
```python
artifacts = expert_team.run(
    project_path,
    maturity,
    previous_sow=sow_text_round1,  # AI sees prior attempt
    feedback=feedback              # AI knows what to fix
)

# AI receives additional context:
"Prior SOW Draft:
[previous attempt with sparse UX section]

Validator Feedback to Address:
Missing sections: UX Requirements. Notes: UX section only 45 words..."

# AI now focuses on enhancing UX section
```

**Round 3: Final Polish (if needed)**
```python
# Same process - AI refines further based on new feedback
```

### Stopping Condition

```python
if complete:
    # All 9 sections present
    # Each section > 100 words
    # Sections have structure (bullets/numbers)
    break  # Exit loop - done!
```

---

## ğŸ“Š DATA FLOW DIAGRAM

```
USER INPUT (Conversation + Documents)
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ui_app.py    â”‚
    â”‚  - Collects   â”‚
    â”‚    input      â”‚
    â”‚  - Tracks     â”‚
    â”‚    status     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼ (calls main.run())
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  main.py          â”‚
    â”‚  - Writes         â”‚
    â”‚    consultation   â”‚
    â”‚    notes          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ProjectAssessor       â”‚
    â”‚ - Scans documents     â”‚
    â”‚ - Returns maturity    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼ (Loop starts)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ExpertTeam            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Read project    â”‚   â”‚
    â”‚  â”‚ documents       â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚        â”‚               â”‚
    â”‚        â–¼               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ For each role:  â”‚   â”‚
    â”‚  â”‚ 1. Build prompt â”‚   â”‚
    â”‚  â”‚ 2. Call model   â”‚   â”‚
    â”‚  â”‚ 3. Get response â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚        â”‚               â”‚
    â”‚        â–¼               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Combine into    â”‚   â”‚
    â”‚  â”‚ deliverables    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼ (artifacts returned)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ValidationEngine       â”‚
    â”‚ - Check presence       â”‚
    â”‚ - Check quality        â”‚
    â”‚ - Check contradictions â”‚
    â”‚ - Evaluate SOW         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
      [SOW complete?]
       â•±           â•²
     NO             YES
      â”‚              â”‚
      â–¼              â–¼
  [Prepare        [Exit loop]
   feedback]          â”‚
      â”‚              â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Exporter              â”‚
    â”‚  - Generate PDFs       â”‚
    â”‚  - Generate diagram    â”‚
    â”‚  - Create DOCX/PDF     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     DELIVERABLES READY
     (Download in UI)
```

---

## ğŸ¯ KEY DESIGN PATTERNS

### 1. **Role-Based Generation**
Instead of one monolithic prompt, work is distributed to specialized roles:
- Each role has clear expertise
- Roles contribute to specific sections
- Natural division of labor (like real consulting)

### 2. **Context Injection**
Every AI call receives full project context:
- Uploaded documents
- Conversation history
- Previous drafts
- Validator feedback

### 3. **Iterative Refinement**
Quality through iteration:
- First pass generates structure
- Validator identifies gaps
- Second/third pass fills gaps
- Guaranteed completeness

### 4. **Provider Abstraction**
Swap AI providers without code changes:
- Mock for testing
- OpenAI for production
- Ollama for local/free
- Same interface, different backends

### 5. **Progress Transparency**
User sees everything:
- Real-time activity log
- Role-by-role progress
- Validation results
- Transcript download

### 6. **Conversational Discovery**
Natural interaction:
- AI leads when documents present
- AI asks targeted questions
- Status tracking shows progress
- Generate enabled when ready

---

## ğŸš€ COMPLETE EXAMPLE SCENARIO

**User:** John has System Architecture, SOW, and Requirements docs for "RL Futures" project

**Step 1: Page Load**
```
- UI detects 3 documents in RLFuturesSystemDocs/project_documents/
- AI analyzes file names
- AI generates cold start:
  "I've reviewed your System Architecture, SOW, and RL Futures System docs. 
   I can see you have a comprehensive microservices architecture planned. 
   Are you committed to this approach, or open to alternatives? Also, your 
   SOW mentions a 6-month timeline - is this still accurate?"
```

**Step 2: Conversation**
```
USER: "Yes, 6 months with a 5-person team. Tech stack is Python/React."

AI checks discovery status:
âœ“ Goals (implied from docs)
âœ“ Tech Stack (Python/React mentioned)
â–¡ Users (not yet discussed)
â–¡ Features (mentioned in SOW but needs validation)
â–¡ Timeline (6 months mentioned)

AI: "Great, Python/React is solid. Who are your primary end users, and 
     what are their key pain points?"

USER: "Financial traders needing real-time market analysis and ML predictions."

AI checks status:
âœ“ Goals
âœ“ Tech Stack
âœ“ Users (traders)
âœ“ Features (real-time analysis, ML)
âœ“ Timeline (6 months)

AI: "âœ… Perfect! I have enough information. Click 'Generate Deliverables' 
     when ready."

[Generate button enables]
```

**Step 3: Generation (User clicks Generate)**
```
[22:30:15] ğŸ“‹ Reading project context...
[22:30:16] ğŸ‘” Strategist analyzing business viability...
[22:30:22] ğŸ“Š Business Analyst gathering requirements...
[22:30:28] ğŸ“… Project Manager outlining timeline...
[22:30:34] ğŸ§  ML/AI Specialist assessing feasibility...
[22:30:40] ğŸ¨ UX Strategist defining user journeys...
[22:30:45] âœ… Discovery Report created

[22:30:46] ğŸ“ Generating Scope of Work...
[22:31:10] âœ… Scope of Work created

[22:31:11] ğŸ—ï¸ Architect designing system components...
[22:31:17] ğŸ’» Full-Stack Developer validating implementation...
[22:31:23] âš™ï¸ DevOps Engineer planning infrastructure...
[22:31:29] ğŸ”’ Security Analyst reviewing compliance...
[22:31:34] âœ… Technical Architecture created

[22:31:35] ğŸ—ºï¸ Creating implementation roadmap...
[22:31:42] âœ… Implementation Roadmap created

[22:31:43] âœ… Validating outputs...
[22:31:44] âœ… SOW completeness gate PASSED

[22:31:45] ğŸ“¦ Generating exports...
[22:31:52] âœ… SOW PDF: outputs/02_scope_of_work.pdf
[22:31:58] âœ… Architecture diagram: outputs/architecture.png
[22:32:05] âœ… DOCX: outputs/final_deliverable.docx
[22:32:12] âœ… PDF: outputs/final_deliverable.pdf

[22:32:13] ğŸ‰ Generation Complete!
```

**Step 4: Outputs**
```
Downloads available:
ğŸ“„ Discovery Report (01_discovery_report.md)
ğŸ“‹ Scope of Work (02_scope_of_work.md)
ğŸ—ï¸ Technical Architecture (03_technical_architecture.md)
ğŸ—ºï¸ Implementation Roadmap (04_implementation_roadmap.md)
âš ï¸ Validation Report (validation_report.md)
ğŸ“Š Architecture Diagram (architecture.png)
ğŸ“¦ Combined DOCX (final_deliverable.docx)
ğŸ“‘ Combined PDF (final_deliverable.pdf)
ğŸ“œ Generation Transcript (generation_transcript.md)
```

---

## ğŸ“ UNDERSTANDING THE CODEBASE

### File Relationships
```
ui_app.py
  â†“ calls
main.py
  â†“ calls
project_assessor.py â†’ [maturity level]
  â†“ passes to
expert_team.py
  â†“ uses
model_client.py â†’ [AI responses]
  â†“ returns artifacts to
validation_engine.py â†’ [validation report]
  â†“ if incomplete
expert_team.py (refinement round)
  â†“ when complete
exporter.py + document_generator.py
  â†“ produces
Final Deliverables
```

### Configuration Flow
```
.env file
  â†“ read by
config.py
  â†“ used by
model_client.py (provider, model, temp)
main.py (output paths)
expert_team.py (model client)
ui_app.py (defaults)
```

### Data Flow
```
User Input (UI) â†’ consultation_notes.md
Uploaded Docs â†’ project_documents/
  â†“ both read by
expert_team._gather_project_context()
  â†“ injected into
Every AI role prompt
  â†“ generates
Artifact markdown files
  â†“ validated by
ValidationEngine
  â†“ exported to
PDF/DOCX/PNG outputs
```

---

## ğŸ’¡ KEY INSIGHTS

### Why 11 Roles?
Real consulting firms have specialists. Each role:
- Has unique expertise
- Uses different vocabulary
- Focuses on different aspects
- Produces higher quality than generic prompts

### Why Iterative?
LLMs are probabilistic:
- First draft might miss details
- Validation catches gaps
- Feedback focuses second attempt
- Iteration ensures completeness

### Why Context Injection?
Every role needs full picture:
- Documents provide baseline
- Conversation adds specifics
- Previous drafts show progress
- Feedback highlights gaps

### Why Provider Abstraction?
Flexibility and cost control:
- Mock for testing (free, fast)
- Ollama for local (free, private)
- OpenAI for production (paid, powerful)
- Easy to switch

---

## ğŸ¯ SUMMARY

**What it does:**
Replaces $50k-$200k consulting engagement with AI automation

**How it works:**
11 specialized AI roles collaborate to produce professional deliverables

**Key innovation:**
Role-based generation + iterative refinement + context injection

**Result:**
Complete consulting package in minutes instead of weeks/months

**Output:**
4 deliverables (Discovery, SOW, Architecture, Roadmap) + validation + exports

**Interface:**
Conversational UI with intelligent question flow and progress tracking

---

This system is essentially a **virtual consulting firm** where each AI role acts as a specialist consultant, working together under the coordination of the main conductor to produce comprehensive, professional project documentation.
